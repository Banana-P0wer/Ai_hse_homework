{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# 02_model_inference_eval.ipynb",
   "id": "b9d7c9a1240c1333"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Генерация имени функции по телу без комментариев (CodeT5+)\n",
    "\n",
    "Используется предобученная модель CodeT5+ без дообучения. На вход подаётся тело функции без комментариев и docstring. Качество оценивается с помощью метрик Exact Match и ROUGE"
   ],
   "id": "a5ce23c75afd8ffa"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-14T19:06:19.253606Z",
     "start_time": "2025-12-14T19:06:19.241607Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import torch\n",
    "import re\n",
    "from datasets import load_from_disk\n",
    "from transformers import AutoTokenizer, AutoModelForSeq2SeqLM\n",
    "import evaluate\n"
   ],
   "id": "e3b63099f5aa6e34",
   "outputs": [],
   "execution_count": 34
  },
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-12-14T19:06:19.268605Z",
     "start_time": "2025-12-14T19:06:19.256606Z"
    }
   },
   "source": [
    "ds_final = load_from_disk(\"artifacts/ds_python_1000_prepared\")\n",
    "print(\"Loaded dataset size:\", len(ds_final))\n",
    "print(\"Columns:\", ds_final.column_names)\n"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded dataset size: 1000\n",
      "Columns: ['repository_name', 'func_path_in_repository', 'func_name', 'whole_func_string', 'language', 'func_code_string', 'func_code_tokens', 'func_documentation_string', 'func_documentation_tokens', 'split_name', 'func_code_url', 'parsed_func_name', 'body_no_comments', 'body_with_comments']\n"
     ]
    }
   ],
   "execution_count": 35
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-14T19:06:21.002521Z",
     "start_time": "2025-12-14T19:06:19.275606Z"
    }
   },
   "cell_type": "code",
   "source": [
    "MODEL_NAME = \"Salesforce/codet5p-220m\"\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME)\n",
    "model = AutoModelForSeq2SeqLM.from_pretrained(MODEL_NAME)\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "model = model.to(device)\n",
    "\n",
    "print(\"CUDA available:\", torch.cuda.is_available())\n",
    "print(\"Torch CUDA version:\", torch.version.cuda)\n"
   ],
   "id": "571c945de062b8f9",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA available: True\n",
      "Torch CUDA version: 11.8\n"
     ]
    }
   ],
   "execution_count": 36
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-14T19:06:21.034521Z",
     "start_time": "2025-12-14T19:06:21.017521Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def make_codet5_input_from_body(body: str) -> str:\n",
    "    lines = body.splitlines()\n",
    "    indented = \"\\n\".join(\n",
    "        (\"    \" + ln if ln.strip() != \"\" else \"\")\n",
    "        for ln in lines\n",
    "    )\n",
    "    return f\"def <extra_id_0>():\\n{indented}\\n\"\n"
   ],
   "id": "55921456d8ad0934",
   "outputs": [],
   "execution_count": 37
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-14T19:06:21.049522Z",
     "start_time": "2025-12-14T19:06:21.036522Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def clean_predicted_name(text: str) -> str:\n",
    "    \"\"\"\n",
    "    Извлекает валидный python-identifier из вывода модели.\n",
    "    \"\"\"\n",
    "    text = text.replace(\"\\n\", \" \").strip()\n",
    "    match = re.search(r\"[A-Za-z_][A-Za-z0-9_]*\", text)\n",
    "    if match:\n",
    "        return match.group(0)\n",
    "    return \"\"\n"
   ],
   "id": "711cdc2257e51a18",
   "outputs": [],
   "execution_count": 38
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-14T19:06:21.064651Z",
     "start_time": "2025-12-14T19:06:21.051522Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def generate_predictions(\n",
    "    dataset,\n",
    "    text_field: str,\n",
    "    max_samples=1000,\n",
    "    batch_size=8,\n",
    "    max_input_length=512,\n",
    "    max_new_tokens=16,\n",
    "):\n",
    "    preds = []\n",
    "    refs = []\n",
    "\n",
    "    ds_slice = dataset.select(range(min(max_samples, len(dataset))))\n",
    "\n",
    "    for start in range(0, len(ds_slice), batch_size):\n",
    "        batch = ds_slice[start:start + batch_size]\n",
    "\n",
    "        inputs = [\n",
    "            make_codet5_input_from_body(x)\n",
    "            for x in batch[text_field]\n",
    "        ]\n",
    "\n",
    "        references = [\n",
    "            name.split(\".\")[-1]\n",
    "            for name in batch[\"func_name\"]\n",
    "        ]\n",
    "\n",
    "        enc = tokenizer(\n",
    "            inputs,\n",
    "            return_tensors=\"pt\",\n",
    "            padding=True,\n",
    "            truncation=True,\n",
    "            max_length=max_input_length,\n",
    "        ).to(device)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            out = model.generate(\n",
    "                **enc,\n",
    "                max_new_tokens=max_new_tokens,\n",
    "                num_beams=5,\n",
    "            )\n",
    "\n",
    "        decoded = tokenizer.batch_decode(out, skip_special_tokens=False)\n",
    "\n",
    "        for s in decoded:\n",
    "            if \"<extra_id_0>\" in s:\n",
    "                part = s.split(\"<extra_id_0>\", 1)[1]\n",
    "                if \"<extra_id_1>\" in part:\n",
    "                    part = part.split(\"<extra_id_1>\", 1)[0]\n",
    "                pred = clean_predicted_name(part)\n",
    "            else:\n",
    "                pred = clean_predicted_name(s)\n",
    "\n",
    "            preds.append(pred)\n",
    "\n",
    "        refs.extend(references)\n",
    "\n",
    "    return preds, refs\n"
   ],
   "id": "45deb5b830f497a8",
   "outputs": [],
   "execution_count": 39
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-14T19:07:15.990925Z",
     "start_time": "2025-12-14T19:06:21.067763Z"
    }
   },
   "cell_type": "code",
   "source": [
    "exact_match = evaluate.load(\"exact_match\")\n",
    "rouge = evaluate.load(\"rouge\")\n",
    "\n",
    "preds, refs = generate_predictions(\n",
    "    ds_final,\n",
    "    text_field=\"body_no_comments\",\n",
    "    max_samples=1000,\n",
    ")\n",
    "\n",
    "em = exact_match.compute(predictions=preds, references=refs)\n",
    "rg = rouge.compute(predictions=preds, references=refs, use_stemmer=False)\n",
    "\n",
    "print(\"Exact Match:\", em)\n",
    "print(\"ROUGE:\", {k: rg[k] for k in [\"rouge1\", \"rouge2\", \"rougeL\"]})\n"
   ],
   "id": "fab390448cb8c7f9",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exact Match: {'exact_match': np.float64(0.143)}\n",
      "ROUGE: {'rouge1': np.float64(0.38367445887445883), 'rouge2': np.float64(0.19806666666666667), 'rougeL': np.float64(0.38083405483405464)}\n"
     ]
    }
   ],
   "execution_count": 40
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "В качестве эталона используется поле `func_name` из датасета CodeSearchNet. Если имя содержит квалификатор класса, берётся только само имя функции. Извлечённое из AST имя используется только для проверки корректности парсинга и не участвует в расчёте метрик",
   "id": "2e06910b505a48bd"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-14T19:07:16.005926Z",
     "start_time": "2025-12-14T19:07:15.996926Z"
    }
   },
   "cell_type": "code",
   "source": [
    "for i in range(5):\n",
    "    print(\"=\" * 80)\n",
    "    print(\"REF :\", refs[i])\n",
    "    print(\"PRED:\", preds[i])\n",
    "    print(\"BODY:\")\n",
    "    print(ds_final[i][\"body_no_comments\"][:200])\n"
   ],
   "id": "758ebfb5e153f366",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "REF : get_vid_from_url\n",
      "PRED: parse_query_param\n",
      "BODY:\n",
      "return match1(url, r'youtu\\.be/([^?/]+)') or \\\n",
      "          match1(url, r'youtube\\.com/embed/([^/?]+)') or \\\n",
      "          match1(url, r'youtube\\.com/v/([^/?]+)') or \\\n",
      "          match1(url, r'youtube\\.com/wa\n",
      "================================================================================\n",
      "REF : sina_xml_to_url_list\n",
      "PRED: parse_xml_data\n",
      "BODY:\n",
      "rawurl = []\n",
      "dom = parseString(xml_data)\n",
      "for node in dom.getElementsByTagName('durl'):\n",
      "        url = node.getElementsByTagName('url')[0]\n",
      "        rawurl.append(url.childNodes[0].data)\n",
      "return rawurl\n",
      "================================================================================\n",
      "REF : makeMimi\n",
      "PRED: md5\n",
      "BODY:\n",
      "strSeed = \"gGddgPfeaf_gzyr\"\n",
      "prehash = upid + \"_\" + strSeed\n",
      "return md5(prehash.encode('utf-8')).hexdigest()\n",
      "================================================================================\n",
      "REF : fc2video_download\n",
      "PRED: fc2video_download_by_upid\n",
      "BODY:\n",
      "hostname = urlparse(url).hostname\n",
      "if not ('fc2.com' in hostname or 'xiaojiadianvideo.asia' in hostname):\n",
      "        return False\n",
      "upid = match1(url, r'.+/content/(\\w+)')\n",
      "fc2video_download_by_upid(upid, ou\n",
      "================================================================================\n",
      "REF : dailymotion_download\n",
      "PRED: download_urls\n",
      "BODY:\n",
      "html = get_content(rebuilt_url(url))\n",
      "info = json.loads(match1(html, r'qualities\":({.+?}),\"'))\n",
      "title = match1(html, r'\"video_title\"\\s*:\\s*\"([^\"]+)\"') or \\\n",
      "            match1(html, r'\"title\"\\s*:\\s*\"([^\"\n"
     ]
    }
   ],
   "execution_count": 41
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### Выводы\n",
    "\n",
    "В эксперименте генерации имён функций по телу без комментариев модель CodeT5+ показала ```Exact Match = 0.143``` и значения ROUGE:\n",
    "``` ROUGE-1 = 0.384, ROUGE-2 = 0.198, ROUGE-L = 0.381. ```\n",
    "\n",
    "Несмотря на низкое значение Exact Match, примеры предсказаний показывают, что модель часто корректно отражает назначение функции и ключевые элементы её семантики. В ряде случаев предсказанное имя отличается от эталона, но остаётся логически согласованным с содержимым функции.\n",
    "\n",
    "Полученные результаты соответствуют ожидаемому уровню для предобученной модели без дообучения и подтверждают пригодность CodeT5+ в качестве baseline-решения для задачи генерации имён функций.\n"
   ],
   "id": "4534107b26ab5aed"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Генерация имени функции с документацией и комментариями\n",
    "\n",
    "Эксперимент повторяется с теми же настройками, но на вход подаётся тело функции вместе с docstring и комментариями. Результаты сравниваются с вариантом, использующим только исполняемый код."
   ],
   "id": "3a55b6e46e97eba5"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-14T19:07:16.021926Z",
     "start_time": "2025-12-14T19:07:16.014926Z"
    }
   },
   "cell_type": "code",
   "source": [
    "assert \"body_with_comments\" in ds_final.column_names\n",
    "\n",
    "print(\"Dataset size:\", len(ds_final))\n",
    "print(\"Using field: body_with_comments\")\n"
   ],
   "id": "227be99be82bedb3",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset size: 1000\n",
      "Using field: body_with_comments\n"
     ]
    }
   ],
   "execution_count": 42
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-14T19:07:16.052925Z",
     "start_time": "2025-12-14T19:07:16.040926Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def make_codet5_input_from_body_with_comments(body: str) -> str:\n",
    "    \"\"\"\n",
    "    Формирует корректный вход для CodeT5+ из тела функции\n",
    "    с документацией и комментариями.\n",
    "    \"\"\"\n",
    "    lines = body.splitlines()\n",
    "    indented = \"\\n\".join(\n",
    "        (\"    \" + ln if ln.strip() != \"\" else \"\")\n",
    "        for ln in lines\n",
    "    )\n",
    "    return f\"def <extra_id_0>():\\n{indented}\\n\"\n"
   ],
   "id": "297cf432dca80c4c",
   "outputs": [],
   "execution_count": 43
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-14T19:07:16.067925Z",
     "start_time": "2025-12-14T19:07:16.060926Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def generate_predictions_with_comments(\n",
    "    dataset,\n",
    "    text_field=\"body_with_comments\",\n",
    "    max_samples=1000,\n",
    "    batch_size=8,\n",
    "    max_input_length=512,\n",
    "    max_new_tokens=16,\n",
    "):\n",
    "    preds = []\n",
    "    refs = []\n",
    "\n",
    "    ds_slice = dataset.select(range(min(max_samples, len(dataset))))\n",
    "\n",
    "    for start in range(0, len(ds_slice), batch_size):\n",
    "        batch = ds_slice[start:start + batch_size]\n",
    "\n",
    "        inputs = [\n",
    "            make_codet5_input_from_body_with_comments(x)\n",
    "            for x in batch[text_field]\n",
    "        ]\n",
    "\n",
    "        references = [\n",
    "            name.split(\".\")[-1]\n",
    "            for name in batch[\"func_name\"]\n",
    "        ]\n",
    "\n",
    "        enc = tokenizer(\n",
    "            inputs,\n",
    "            return_tensors=\"pt\",\n",
    "            padding=True,\n",
    "            truncation=True,\n",
    "            max_length=max_input_length,\n",
    "        ).to(device)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            out = model.generate(\n",
    "                **enc,\n",
    "                max_new_tokens=max_new_tokens,\n",
    "                num_beams=5,\n",
    "            )\n",
    "\n",
    "        decoded = tokenizer.batch_decode(out, skip_special_tokens=False)\n",
    "\n",
    "        for s in decoded:\n",
    "            if \"<extra_id_0>\" in s:\n",
    "                part = s.split(\"<extra_id_0>\", 1)[1]\n",
    "                if \"<extra_id_1>\" in part:\n",
    "                    part = part.split(\"<extra_id_1>\", 1)[0]\n",
    "                pred = clean_predicted_name(part)\n",
    "            else:\n",
    "                pred = clean_predicted_name(s)\n",
    "\n",
    "            preds.append(pred)\n",
    "\n",
    "        refs.extend(references)\n",
    "\n",
    "    return preds, refs\n"
   ],
   "id": "3f136ef95fe8a643",
   "outputs": [],
   "execution_count": 44
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-14T19:08:14.726996Z",
     "start_time": "2025-12-14T19:07:16.072926Z"
    }
   },
   "cell_type": "code",
   "source": [
    "exact_match = evaluate.load(\"exact_match\")\n",
    "rouge = evaluate.load(\"rouge\")\n",
    "\n",
    "preds_c, refs_c = generate_predictions_with_comments(\n",
    "    ds_final,\n",
    "    text_field=\"body_with_comments\",\n",
    "    max_samples=1000,\n",
    ")\n",
    "\n",
    "em_c = exact_match.compute(predictions=preds_c, references=refs_c)\n",
    "rg_c = rouge.compute(predictions=preds_c, references=refs_c, use_stemmer=False)\n",
    "\n",
    "print(\"Exact Match:\", em_c)\n",
    "print(\"ROUGE:\", {k: rg_c[k] for k in [\"rouge1\", \"rouge2\", \"rougeL\"]})\n"
   ],
   "id": "581fcd72e2fd7c92",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exact Match: {'exact_match': np.float64(0.184)}\n",
      "ROUGE: {'rouge1': np.float64(0.4666515151515154), 'rouge2': np.float64(0.2671956349206349), 'rougeL': np.float64(0.4652629509379509)}\n"
     ]
    }
   ],
   "execution_count": 45
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### Интерпретация метрик\n",
    "\n",
    "Значение Exact Match ниже ориентировочного, что ожидаемо для генеративной модели без дообучения. На результат влияют beam search, ограничение длины входа и стохастическая природа генерации. Это свойство модели, а не ошибка реализации."
   ],
   "id": "dca5f69db3836637"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-14T19:08:14.757997Z",
     "start_time": "2025-12-14T19:08:14.743996Z"
    }
   },
   "cell_type": "code",
   "source": [
    "for i in range(5):\n",
    "    print(\"=\" * 80)\n",
    "    print(\"REF :\", refs_c[i])\n",
    "    print(\"PRED:\", preds_c[i])\n",
    "    print(\"BODY:\")\n",
    "    print(ds_final[i][\"body_with_comments\"][:300])\n"
   ],
   "id": "bf1203e55f03e606",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "REF : get_vid_from_url\n",
      "PRED: extract_video_id\n",
      "BODY:\n",
      "\"\"\"Extracts video ID from URL.\n",
      "        \"\"\"\n",
      "        return match1(url, r'youtu\\.be/([^?/]+)') or \\\n",
      "          match1(url, r'youtube\\.com/embed/([^/?]+)') or \\\n",
      "          match1(url, r'youtube\\.com/v/([^/?]+)') or \\\n",
      "          match1(url, r'youtube\\.com/watch/([^/?]+)') or \\\n",
      "          parse_query_param(u\n",
      "================================================================================\n",
      "REF : sina_xml_to_url_list\n",
      "PRED: parse_url_list\n",
      "BODY:\n",
      "\"\"\"str->list\n",
      "    Convert XML to URL List.\n",
      "    From Biligrab.\n",
      "    \"\"\"\n",
      "    rawurl = []\n",
      "    dom = parseString(xml_data)\n",
      "    for node in dom.getElementsByTagName('durl'):\n",
      "        url = node.getElementsByTagName('url')[0]\n",
      "        rawurl.append(url.childNodes[0].data)\n",
      "    return rawurl\n",
      "================================================================================\n",
      "REF : makeMimi\n",
      "PRED: md5\n",
      "BODY:\n",
      "\"\"\"From http://cdn37.atwikiimg.com/sitescript/pub/dksitescript/FC2.site.js\n",
      "    Also com.hps.util.fc2.FC2EncrptUtil.makeMimiLocal\n",
      "    L110\"\"\"\n",
      "    strSeed = \"gGddgPfeaf_gzyr\"\n",
      "    prehash = upid + \"_\" + strSeed\n",
      "    return md5(prehash.encode('utf-8')).hexdigest()\n",
      "================================================================================\n",
      "REF : fc2video_download\n",
      "PRED: fc2video_download_by_upid\n",
      "BODY:\n",
      "\"\"\"wrapper\"\"\"\n",
      "    #'http://video.fc2.com/en/content/20151021bTVKnbEw'\n",
      "    #'http://xiaojiadianvideo.asia/content/20151021bTVKnbEw'\n",
      "    #'http://video.fc2.com/ja/content/20151021bTVKnbEw'\n",
      "    #'http://video.fc2.com/tw/content/20151021bTVKnbEw'\n",
      "    hostname = urlparse(url).hostname\n",
      "    if not ('fc2.co\n",
      "================================================================================\n",
      "REF : dailymotion_download\n",
      "PRED: download_urls\n",
      "BODY:\n",
      "\"\"\"Downloads Dailymotion videos by URL.\n",
      "    \"\"\"\n",
      "\n",
      "    html = get_content(rebuilt_url(url))\n",
      "    info = json.loads(match1(html, r'qualities\":({.+?}),\"'))\n",
      "    title = match1(html, r'\"video_title\"\\s*:\\s*\"([^\"]+)\"') or \\\n",
      "            match1(html, r'\"title\"\\s*:\\s*\"([^\"]+)\"')\n",
      "    title = unicodize(title)\n",
      "\n",
      "  \n"
     ]
    }
   ],
   "execution_count": 46
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### Анализ результатов генерации\n",
    "\n",
    "Для генерации имён функций по телу без комментариев получены значения метрик:\n",
    "```\n",
    "Exact Match = 0.143\n",
    "ROUGE-1 = 0.384\n",
    "ROUGE-2 = 0.198\n",
    "ROUGE-L = 0.381\n",
    "```\n",
    "\n",
    "Низкое значение Exact Match связано со строгой формулировкой метрики и тем, что для одной и той же функции возможно несколько корректных имён. При этом значения ROUGE показывают, что модель часто воспроизводит ключевые смысловые компоненты эталонного имени.\n",
    "\n",
    "Примеры выше показывают случаи, когда предсказанное имя отличается от эталона формально, но отражает назначение функции и её семантику."
   ],
   "id": "8d387468f0a9429e"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
